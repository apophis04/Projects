{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, get_linear_schedule_with_warmup\n",
    "from datasets import Dataset\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import re\n",
    "import logging\n",
    " \n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_reviews.csv\")\n",
    "\n",
    "df.dropna(subset=['review'], inplace=True)\n",
    "\n",
    "def assign_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 1  # Positive\n",
    "    elif rating == 3:\n",
    "        return 0  # Neutral\n",
    "    else:\n",
    "        return -1  # Negative\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(assign_sentiment)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    words = [word for word in text.split() if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert_sentiment'] = df['sentiment'].apply(lambda x: 0 if x == -1 else x)\n",
    "hf_dataset = Dataset.from_pandas(df[['cleaned_review', 'bert_sentiment']])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['cleaned_review'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "hf_dataset = hf_dataset.map(tokenize_function, batched=True, remove_columns=['cleaned_review'])\n",
    "hf_dataset = hf_dataset.rename_column(\"bert_sentiment\", \"labels\")\n",
    "hf_dataset = hf_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "print(hf_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\"\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    report = classification_report(labels, preds)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_dataset[\"train\"],\n",
    "    eval_dataset=hf_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df['cleaned_review'][i:i + batch_size].tolist()\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "    results.extend(predictions)\n",
    "\n",
    "df['bert_sentiment'] = results\n",
    "\n",
    "print(df[['cleaned_review', 'bert_sentiment']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df['bert_sentiment'].value_counts()\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "daily_sentiment = df.groupby('date')['bert_sentiment'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment.values)\n",
    "plt.title(\"Average Sentiment Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Sentiment\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "arima_model = ARIMA(daily_sentiment, order=(1, 1, 1))\n",
    "arima_result = arima_model.fit()\n",
    "print(arima_result.summary())\n",
    "\n",
    "forecast = arima_result.forecast(steps=10)\n",
    "print(\"Forecasted Sentiments:\", forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Statistical Analysis of Sentiments\n",
    "sentiment_array = df['bert_sentiment'].values\n",
    "print(\"Sentiment Statistics:\")\n",
    "print(\"Mean Sentiment:\", np.mean(sentiment_array))\n",
    "print(\"Median Sentiment:\", np.median(sentiment_array))\n",
    "print(\"Standard Deviation:\", np.std(sentiment_array))\n",
    "\n",
    "# 2. Binning Sentiments\n",
    "sentiment_bins = np.histogram(df['bert_sentiment'], bins=3)\n",
    "print(\"Sentiment Distribution Bins:\", sentiment_bins)\n",
    "\n",
    "# 3. Advanced Feature Engineering\n",
    "def extract_review_length(reviews):\n",
    "    \"\"\"Calculate review lengths using NumPy\"\"\"\n",
    "    return np.array([len(review.split()) for review in reviews])\n",
    "\n",
    "df['review_length'] = extract_review_length(df['cleaned_review'])\n",
    "\n",
    "# Correlation between review length and sentiment\n",
    "length_sentiment_correlation = np.corrcoef(df['review_length'], df['bert_sentiment'])[0, 1]\n",
    "print(\"Correlation between Review Length and Sentiment:\", length_sentiment_correlation)\n",
    "\n",
    "# 4. Random Sampling for Model Validation\n",
    "np.random.seed(42)\n",
    "random_sample_indices = np.random.choice(len(df), size=100, replace=False)\n",
    "sample_reviews = df.iloc[random_sample_indices]\n",
    "\n",
    "# 5. One-hot Encoding of Sentiments\n",
    "sentiment_one_hot = np.eye(3)[df['bert_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    print(f\"\\n{name} Classifier Results:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def predict_sentiment_tfidf(reviews, vectorizer, classifier):\n",
    "    reviews_tfidf = vectorizer.transform(reviews)\n",
    "\n",
    "    predictions = classifier.predict(reviews_tfidf)\n",
    "\n",
    "    sentiment_map = {1: \"Positive\", 0: \"Neutral\", -1: \"Negative\"}\n",
    "\n",
    "    for review, pred in zip(reviews, predictions):\n",
    "        print(f\"Review: {review}\")\n",
    "        print(f\"Predicted Sentiment: {sentiment_map[pred]}\\n\")\n",
    "\n",
    "# Example usage\n",
    "new_reviews = [\n",
    "    \"The camera quality is amazing and the battery life is impressive!\",\n",
    "    \"The product was okay, but the delivery was late.\",\n",
    "    \"I am very disappointed with the purchase. It broke within a week.\"\n",
    "]\n",
    "\n",
    "best_model = classifiers['Decision Tree']\n",
    "predict_sentiment_tfidf(new_reviews, tfidf_vectorizer, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text_series, title, sentiment_type=None):\n",
    "    \"\"\"\n",
    "    Generate a WordCloud visualization for a given text series.\n",
    "    \n",
    "    :param text_series: Pandas Series of text data\n",
    "    :param title: Title for the WordCloud plot\n",
    "    :param sentiment_type: Optional filter for specific sentiment type\n",
    "    \"\"\"\n",
    "    if sentiment_type is not None:\n",
    "        text_series = text_series[df['sentiment'] == sentiment_type]\n",
    "    \n",
    "    text = ' '.join(text_series)\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white', \n",
    "        stopwords=stop_words,\n",
    "        max_words=50000,\n",
    "        colormap='viridis'\n",
    "    ).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(df['cleaned_review'], 'Overall Most Frequent Words')\n",
    "\n",
    "# WordCloud for Positive Reviews\n",
    "generate_wordcloud(df['cleaned_review'], 'Most Frequent Words in Positive Reviews', sentiment_type=1)\n",
    "\n",
    "# WordCloud for Neutral Reviews\n",
    "generate_wordcloud(df['cleaned_review'], 'Most Frequent Words in Neutral Reviews', sentiment_type=0)\n",
    "\n",
    "# WordCloud for Negative Reviews\n",
    "generate_wordcloud(df['cleaned_review'], 'Most Frequent Words in Negative Reviews', sentiment_type=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output_with_sentiments.csv\", index=False)\n",
    "print(\"Results saved to output_with_sentiments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_reviews = [\n",
    "    \"The camera quality is amazing and the battery life is impressive!\",\n",
    "    \"The product was okay, but the delivery was late.\",\n",
    "    \"I am very disappointed with the purchase. It broke within a week.\"\n",
    "]\n",
    "\n",
    "best_model = classifiers['Decision Tree'] # Other options: 'Naive Bayes', 'Random Forest'\n",
    "predict_sentiment_tfidf(new_reviews, tfidf_vectorizer, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "monthly_trends = df.resample('M', on='date')['bert_sentiment'].mean().reset_index()\n",
    "\n",
    "print(\"Monthly Sentiment Trends:\")\n",
    "print(monthly_trends)\n",
    "\n",
    "if len(monthly_trends) < 10:\n",
    "    print(\"Warning: Not enough data points for reliable ARIMA forecasting\")\n",
    "else:\n",
    "    try:\n",
    "        model = ARIMA(monthly_trends['bert_sentiment'], order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        print(\"\\nARIMA Model Summary:\")\n",
    "        print(model_fit.summary())\n",
    "\n",
    "        # Forecast next 12 months\n",
    "        forecast_steps = 12\n",
    "        forecast = model_fit.forecast(steps=forecast_steps)\n",
    "\n",
    "        last_date = monthly_trends['date'].iloc[-1]\n",
    "        forecast_dates = pd.date_range(start=last_date, periods=forecast_steps+1, freq='M')[1:]\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'date': forecast_dates,\n",
    "            'forecasted_sentiment': forecast\n",
    "        })\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.plot(monthly_trends['date'], monthly_trends['bert_sentiment'], \n",
    "                 label='Historical Sentiment', color='blue')\n",
    "\n",
    "        plt.plot(forecast_df['date'], forecast_df['forecasted_sentiment'], \n",
    "                 label='Forecasted Sentiment', color='red', linestyle='--')\n",
    "\n",
    "        try:\n",
    "            forecast_ci = model_fit.get_forecast(steps=forecast_steps)\n",
    "            conf_int = forecast_ci.conf_int()\n",
    "\n",
    "            conf_int_array = conf_int.to_numpy() if hasattr(conf_int, 'to_numpy') else np.array(conf_int)\n",
    "\n",
    "            plt.fill_between(\n",
    "                forecast_dates, \n",
    "                conf_int_array[:, 0], \n",
    "                conf_int_array[:, 1], \n",
    "                color='pink', \n",
    "                alpha=0.3, \n",
    "                label='95% Confidence Interval'\n",
    "            )\n",
    "        except Exception as ci_error:\n",
    "            print(\"Could not plot confidence interval:\", ci_error)\n",
    "\n",
    "        plt.title('Monthly Sentiment Trends with ARIMA Forecast')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Sentiment Score')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nForecast for Next 12 Months:\")\n",
    "        print(forecast_df)\n",
    "\n",
    "    except Exception as model_error:\n",
    "        print(\"Error in ARIMA modeling:\", model_error)\n",
    "        print(\"Suggestion: Try different ARIMA order or check data preprocessing\")\n",
    "\n",
    "if 'monthly_trends' in locals():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(monthly_trends['date'], monthly_trends['bert_sentiment'])\n",
    "    plt.title('Monthly Sentiment Trends')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Sentiment Score')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
